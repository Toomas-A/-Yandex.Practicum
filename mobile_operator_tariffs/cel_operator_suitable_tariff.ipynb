{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов мобильной связи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оператор мобильной связи выяснил, что многие клиенты пользуются архивными тарифами. Необходимо  построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра».\n",
    "\n",
    "Предоставлены данные о поведении клиентов, которые перешли на тарифы «Смарт» и «Ультра». Нужно построить модель для задачи классификации, которая выберет подходящий из этих тариф. Данные уже были предобработаны в аналитическом проекте `cellular operator tariffs analysis`.\n",
    "\n",
    "Необходимо постройть модель с максимально большим значением *accuracy*, минимальная доля правильных ответов - 0.75. \n",
    "\n",
    "В наборе данных информация о поведении одного пользователя за месяц. Известно:  \n",
    "`сalls` — количество звонков,  \n",
    "`minutes` — суммарная длительность звонков в минутах,  \n",
    "`messages` — количество sms-сообщений,  \n",
    "`mb_used` — израсходованный интернет-трафик в Мб,  \n",
    "`is_ultra` — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0).\n",
    "\n",
    "#### План действий:  \n",
    "1) Откроем файл с данными `datasets/users_behavior.csv` и изучим его.   \n",
    "2) Разделим исходные данные на обучающую, валидационную и тестовую выборки.  \n",
    "3) Исследуем качество разных моделей, меняя гиперпараметры.  \n",
    "4) Проверим качество модели на тестовой выборке.  \n",
    "5) Проверим модели на вменяемость.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Откроем файлы с данными и изучим информацию\n",
    "\n",
    "\n",
    "Импортируем все необходимые для анализа и обучения библиотеки. Откроем файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "import warnings # отключение предупреждений\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3209</td>\n",
       "      <td>3209</td>\n",
       "      <td>122.0</td>\n",
       "      <td>910.98</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35124.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>3210</td>\n",
       "      <td>25.0</td>\n",
       "      <td>190.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3275.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3211</td>\n",
       "      <td>3211</td>\n",
       "      <td>97.0</td>\n",
       "      <td>634.44</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13974.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3212</td>\n",
       "      <td>3212</td>\n",
       "      <td>64.0</td>\n",
       "      <td>462.32</td>\n",
       "      <td>90.0</td>\n",
       "      <td>31239.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3213</td>\n",
       "      <td>3213</td>\n",
       "      <td>80.0</td>\n",
       "      <td>566.09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29480.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3214 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  calls  minutes  messages   mb_used  is_ultra\n",
       "0              0   40.0   311.90      83.0  19915.42         0\n",
       "1              1   85.0   516.75      56.0  22696.96         0\n",
       "2              2   77.0   467.66      86.0  21060.45         0\n",
       "3              3  106.0   745.53      81.0   8437.39         1\n",
       "4              4   66.0   418.74       1.0  14502.75         0\n",
       "...          ...    ...      ...       ...       ...       ...\n",
       "3209        3209  122.0   910.98      20.0  35124.90         1\n",
       "3210        3210   25.0   190.36       0.0   3275.61         0\n",
       "3211        3211   97.0   634.44      70.0  13974.06         0\n",
       "3212        3212   64.0   462.32      90.0  31239.78         0\n",
       "3213        3213   80.0   566.09       6.0  29480.52         1\n",
       "\n",
       "[3214 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datasets/users_behavior.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашей выборке представлено 3214 объектов и 5 признаков. Целевой признак, который нужно предсказать, — это тариф (`is_ultra`).\n",
    "\n",
    "В данном случае целевой признак категориальный, будем решаеть задачу бинарной классификации выбора тарифа — «Ультра» или «Смарт»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Разбиваем данные на выборки\n",
    "\n",
    "- Разобьем наш датасет на на обучающую, валидационную и тестовую выборки при помощи NumPy.split в пропорции 60%-20%-20%.\n",
    "- Разделим их на признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, validate, test = np.split(data.sample(frac=1), [int(.6*len(data)), int(.8*len(data))]) # разбивка 60%-20%-20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train.drop(['is_ultra'], axis=1) # тренировочная выборка\n",
    "target_train = train['is_ultra']\n",
    "\n",
    "features_validate = validate.drop(['is_ultra'], axis=1) # валидационная выборка\n",
    "target_validate = validate['is_ultra']\n",
    "\n",
    "features_test = test.drop(['is_ultra'], axis=1) # тестовая выброка\n",
    "target_test = test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Исследуйте модели\n",
    "\n",
    "Используем для обучения модели следующие алгоритмы:\n",
    "\n",
    "- DecisionTreeClassifier\n",
    "- RandomForestClassifier\n",
    "- LogisticRegression.\n",
    "\n",
    "Обучим модель и проверим алгоритмы на валидационной выборке. \n",
    "\n",
    "Чтобы улучшить правильность предсказаний нашей модели необходимо подобрать соответствующий гиперпараметр `maх_depth` и `n_estimators`, при этом соблюсти баланс между переобучением и недообучением. Для автоматизации процесса, создадим цикл подставляющий разные значения и сравним качество моделей в разных вариантах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.7433903576982893\n",
      "max_depth = 2 : 0.776049766718507\n",
      "max_depth = 3 : 0.7916018662519441\n",
      "max_depth = 4 : 0.776049766718507\n",
      "max_depth = 5 : 0.7729393468118196\n",
      "max_depth = 6 : 0.7869362363919129\n",
      "max_depth = 7 : 0.7931570762052877\n",
      "max_depth = 8 : 0.7838258164852255\n",
      "max_depth = 9 : 0.7978227060653188\n",
      "max_depth = 10 : 0.7947122861586314\n",
      "max_depth = 11 : 0.7916018662519441\n",
      "max_depth = 12 : 0.7807153965785381\n",
      "max_depth = 13 : 0.7651632970451011\n",
      "max_depth = 14 : 0.7511664074650077\n",
      "max_depth = 15 : 0.7480559875583204\n"
     ]
    }
   ],
   "source": [
    "for mxd in range(1, 16): # DecisionTreeClassifier\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth = mxd)\n",
    "    model.fit(features_train, target_train)\n",
    "    test_predictions_dtc = model.predict(features_validate)\n",
    "    test_accuracy_dtc = accuracy_score(target_validate, test_predictions_dtc)\n",
    "    print('max_depth =', mxd, ':', test_accuracy_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimator = 1 : 0.7325038880248833\n",
      "n_estimator = 2 : 0.7822706065318819\n",
      "n_estimator = 3 : 0.7744945567651633\n",
      "n_estimator = 4 : 0.7853810264385692\n",
      "n_estimator = 5 : 0.7651632970451011\n",
      "n_estimator = 6 : 0.7822706065318819\n",
      "n_estimator = 7 : 0.7884914463452566\n",
      "n_estimator = 8 : 0.7962674961119751\n",
      "n_estimator = 9 : 0.7791601866251944\n",
      "n_estimator = 10 : 0.7931570762052877\n",
      "n_estimator = 11 : 0.7744945567651633\n",
      "n_estimator = 12 : 0.7807153965785381\n",
      "n_estimator = 13 : 0.7791601866251944\n",
      "n_estimator = 14 : 0.7869362363919129\n",
      "n_estimator = 15 : 0.7807153965785381\n"
     ]
    }
   ],
   "source": [
    "for nest in range(1, 16): # RandomForestClassifier\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=nest)\n",
    "    model.fit(features_train, target_train)\n",
    "    test_predictions_rfc = model.predict(features_validate)\n",
    "    test_accuracy_rfc = accuracy_score(target_validate, test_predictions_rfc)\n",
    "    print('n_estimator =', nest, ':', test_accuracy_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6858475894245724"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LogisticRegression(random_state=12345) # LogisticRegression\n",
    "model_lr.fit(features_train, target_train)\n",
    "test_predictions_lr = model_lr.predict(features_validate)\n",
    "test_accuracy_lr = accuracy_score(target_validate, test_predictions_lr)\n",
    "test_accuracy_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальная доля правильных ответов достигается при глубине `max_depth` равной 3-4 и при количестве оценщиков `n_estimators` - 9-10. При этом лучше работают модели DecisionTreeClassifier и RandomForestClassifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проверка моделей на тестовой выборке\n",
    "\n",
    "Использум параметры `max_depth` и `n_estimators`, показавшие максимальные доли правильных ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8118195956454122"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dtc = DecisionTreeClassifier(random_state=12345, max_depth = 4)\n",
    "model_dtc.fit(features_train, target_train)\n",
    "model_dtc.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8133748055987559"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rfc = RandomForestClassifier(random_state=12345, n_estimators=9)\n",
    "model_rfc.fit(features_train, target_train)\n",
    "model_rfc.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262830482115086"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, тестовая выборка подтвердила правильность выбора алгоритма обучения - DecisionTreeClassifier и RandomForestClassifier. Мы достигли значения доли правильных ответов (accuracy) - 0.78-0.8.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (бонус) Проверка модели на адекватность\n",
    "\n",
    "Используем классификатор DummyClassifier в качестве сравнения с выбранным алгоритмом модели. Стратегия (`strategy`) будет генерировать прогнозы равномерно случайным образом - «uniform»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5334370139968896 против 0.8118195956454122\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='uniform')\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "# DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.predict(features_test)\n",
    "print(dummy_clf.score(features_test, target_test), 'против', model_dtc.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша модель работает явно лучше!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
